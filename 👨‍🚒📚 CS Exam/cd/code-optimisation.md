---
description: Made By Me üíö
layout:
  width: wide
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: false
  metadata:
    visible: false
  tags:
    visible: true
---

# Code Optimisation

#### AST vs DAG vs CFG Graphs

**Directed Acyclic Graph (DAG) ‚≠ê**

* Used for **code optimization** inside a **basic block**
* Graph with **directed edges** and **no cycles**
* Nodes represent variables, constants, or operations
* Same subexpression ‚Üí **single node**
* Helps in: ‚≠ê
  * \==Common subexpression elimination==
  * \==Dead code elimination==
  * Code motion
* Scope: **local optimization only**

**Abstract Syntax Tree (AST)**

* Tree representation of **program syntax**
* Generated after parsing
* Interior nodes ‚Üí operators / constructs
* Leaf nodes ‚Üí identifiers / constants
* Removes unnecessary grammar symbols (unlike parse tree)
* Used for: ‚≠ê
  * \==Syntax analysis==
  * \==Semantic analysis==
  * Intermediate code generation
* Structure: **tree (hierarchical)**

**Control Flow Graph (CFG) ‚≠ê**

* Graph representing **flow of control**
* Nodes ‚Üí basic blocks
* Edges ‚Üí possible control transfers
* Used for:
  * Loop detection
  * Reachability analysis
  * Data flow analysis
  * Global optimization
* May contain **cycles** (loops)

**Key Differences (Exam-Oriented)**

| Feature      | DAG                      | AST            | CFG              |
| ------------ | ------------------------ | -------------- | ---------------- |
| Structure    | Graph                    | ==Tree==       | Graph            |
| Cycles       | Not allowed              | Not allowed    | ==Allowed==      |
| Level        | Expression / Basic block | Program syntax | Program flow     |
| Optimization | ==Yes (local)==          | No             | ==Yes (global)== |
| Focus        | ==Computation==          | Syntax         | Control          |

**One-Line Memory Hooks**

* **AST** ‚Üí how code is written ‚Üí for ==meaning==
* **DAG** ‚Üí how expressions are optimized ‚Üí for ==efficiency==
* **CFG** ‚Üí how control flows ‚Üí for ==execution flow==

***

#### Nodes and Edges in DAG

\==Directed Acyclic Graph (DAG)== is used to ==represent **basic blocks**== in compiler optimization to ==eliminate redundant computations.==

**Nodes**

Each node represents:

* A variable (leaf node)
* A constant (leaf node)
* An operator with operands (`+`, `-`, `*`, `/`, etc.) So,
* \==**Number of nodes== = ==No. of distinct variables== + ==No. of constants== + ==No. of distinct operations**==
* Common subexpressions share the **same node**

**Edges**

Edges represent **data dependency**:

* **Directed** from ==operand ‚Üí operator==
* If an operator has `k` operands, it contributes `k` incoming edges So,
* \==**Number of edges== = ==sum of operands of all operator nodes==**
* Unary operator ‚Üí 1 edge
* Binary operator ‚Üí 2 edges

**Key Point**

DAG minimizes nodes and edges by:

* Merging identical subexpressions
* Avoiding recomputation

**Example**

```
a = b + c
d = b + c
```

* Nodes: `b`, `c`, `(b+c)`, `a`, `d` ‚Üí **5 nodes**
* Edges: `b ‚Üí (b+c)`, `c ‚Üí (b+c)`, `(b+c) ‚Üí a`, `(b+c) ‚Üí d` ‚Üí **4 edges**

```
      b     c
       \   /
        \ /
       ( + )
       /   \
      a     d
```

Best view: **Fewer nodes and edges = more optimized code**

***

#### Data Flow Analysis & Code Optimisation

**Data Flow Analysis (DFA) ‚≠ê**

* Technique to ==collect information about **program variables and expressions**== at different program points
* Performed on ==**Control Flow Graph (CFG)**==
* Foundation for **global code optimization**
* Based on **iterative equations** until fixed point

**Basic Terms**

* **Basic Block**: maximal sequence of statements with single entry and exit
* **CFG Node**: basic block
* **CFG Edge**: possible control transfer
* \==**`IN[B]`**: information before block B==
* \==**`OUT[B]`**: information after block B==
* **`GEN[B]`**: information generated by block B
* **`KILL[B]`**: information invalidated by block B

**Direction of Analysis**

* \==**Forward== Analysis**: information ==flows along control flow==\
  Example: Available Expression
* \==**Backward== Analysis**: information ==flows opposite to control flow==\
  Example: Live Variable

**Data Flow Equation (General)**

*   Forward:

    ```
    IN[B]  = ‚ãÇ / ‚ãÉ OUT[P]  for all predecessors P
    OUT[B] = GEN[B] ‚à™ (IN[B] ‚àí KILL[B])
    ```
*   Backward:

    ```
    OUT[B] = ‚ãÇ / ‚ãÉ IN[S]  for all successors S
    IN[B]  = GEN[B] ‚à™ (OUT[B] ‚àí KILL[B])
    ```

**Meet Operator**

* **Union (‚ãÉ)**: may analysis
* **Intersection (‚ãÇ)**: must analysis

**A. ==Live Variable Analysis**== ‚≠ê

* \==Variable is **live**== if its ==value may be used later==
* Type: ==**Backward analysis**==
* Meet: ==**Union**==
* GEN: variables used before definition
* KILL: variables defined
* Used for: ==**Dead Code Elimination**==

**B. Available Expression Analysis** ‚≠ê

* \==Expression is available== if ==already computed and not killed
* Type: ==**Forward analysis**==
* Meet: ==**Intersection**==
* GEN: expressions computed
* KILL: operands redefined
* Used for: ==**Common Sub-expression Elimination**==

**Code Optimization**

* Process of improving code **without changing semantics**
* Goal: reduce execution time, memory, power
* Performed on **Intermediate Representation (IR)**

**Types of Optimization**

1. **Machine Independent**
2. **Machine Dependent**

**A. Local Optimization**

* Applied within a **basic block**
* Techniques:
  * \==Common sub-expression elimination== (via DAG)
  * \==Constant folding==
  * \==Dead code elimination==

**B. Global Optimization**

* Applied across **multiple basic blocks**
* Requires **Data Flow Analysis**
* Techniques:
  * \==Live variable based== ==dead code elimination==
  * Global sub-expression elimination
  * \==Code motion== ‚≠ê

**C. Loop Optimization**

* Improves frequently executed loops
* Techniques:
  1. \==**Loop Invariant Code Motion**== ‚≠ê
  2. \==**Strength Reduction**== ‚≠ê Example: `i * 2 ‚Üí i + i` ‚≠ê
  3. \==**Induction Variable Elimination**==

**Techniques:** ‚≠ê‚≠ê

1. **Dead Code Elimination** ‚Äì Removes statements whose results are never used (based on live variable analysis)
2. **Common Sub-Expression Elimination** ‚Äì Computes an expression once and reuses its value instead of recomputing
3. **Loop Invariant Code Motion** ‚Äì Moves computations that do not change inside a loop to outside the loop
4. **Strength Reduction** ‚Äì Replaces expensive operations with cheaper ones (e.g., `*` ‚Üí `+`)
5. **Induction Variable Elimination** ‚Äì Removes extra loop variables derivable from a primary induction variable
6. **Code Motion** ‚Äì ==Relocates computations to points== ==where they execute fewer times== without changing semantics
7. **Constant Folding** ‚Äì ==Evaluates constant expressions at compile time==
8. **Constant Propagation** ‚Äì ==Replaces variables with known constant values==
9. **Copy Propagation** ‚Äì ==Replaces variables that are simple copies with the original variable==
10. **Algebraic Simplification** ‚Äì Uses algebraic identities to simplify expressions
11. **Unreachable Code Elimination** ‚Äì Removes code that can never be executed
12. **Peephole Optimization** ‚Äì Performs small local optimizations on a short sequence of instructions

**GATE Focus Points**

* Direction of analysis
* Meet operator choice
* GEN/KILL construction
* Mapping:\
  DFA ‚Üí enables optimization\
  Optimization ‚Üí improves performance

**One-Line Memory Rule**

* **CFG + DFA = Global Optimization**
